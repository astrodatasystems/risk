# =============================================================
# Data Catalog — Kedro dataset declarations
# =============================================================
# Naming convention follows the Medallion architecture:
#   01_raw      = Bronze (raw, untouched)
#   02_intermediate = Silver (cleaned, typed)
#   03_primary  = Gold (aggregated, business-ready)
#
# Intermediate DataFrames (bronze_combined, bronze_selected, etc.)
# are NOT listed here — Kedro keeps them in memory during the run.
# Only datasets that need to be persisted to disk are registered.
# =============================================================

# ── Silver output (data_processing pipeline) ─────────────────
storm_events_silver:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/storm_events_silver.parquet
  save_args:
    engine: pyarrow
    index: false

# ── Gold output (feature_engineering pipeline) ─────────────────
storm_events_gold:
  type: pandas.ParquetDataset
  filepath: data/04_feature/storm_events_gold.parquet
  save_args:
    engine: pyarrow
    index: false

# ── Model training pipeline datasets ──────────────────────────
training_data:
  type: pandas.ParquetDataset
  filepath: data/05_model_input/training_data.parquet
  save_args:
    engine: pyarrow
    index: false

damage_model_artifact:
  type: pickle.PickleDataset
  filepath: data/06_models/damage_model.joblib
  backend: joblib

evaluation_metrics:
  type: json.JSONDataset
  filepath: data/08_reporting/evaluation_metrics.json

tier_thresholds:
  type: json.JSONDataset
  filepath: data/06_models/tier_thresholds.json

feature_importance:
  type: pandas.ParquetDataset
  filepath: data/08_reporting/feature_importance.parquet
  save_args:
    engine: pyarrow
    index: false
